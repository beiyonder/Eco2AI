{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellcome to **eco2ai** tutorial\n",
    "\n",
    "Install the following libraries into your python environment, if they are not already installed:\n",
    "\n",
    "***pip install numpy pandas matplotlib pillow pytorch***\n",
    "\n",
    "Install the eco2ai library in your python environment:\n",
    "\n",
    "***pip install eco2ai***\n",
    "\n",
    "and run this jupyter notebook as a usage example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eco2ai\n",
    "from eco2ai import track\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Preparing MNIST Dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Display some example images\n",
    "fig, axs = plt.subplots(1, 10, figsize=(25, 3))\n",
    "for i in range(10):\n",
    "    label_indexes = [idx for idx, (_, label) in enumerate(train_dataset) if label == i]\n",
    "    index = random.choice(label_indexes)\n",
    "    img, _ = train_dataset[index]\n",
    "    axs[i].imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(1)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = eco2ai.Tracker(project_name=\"mnist\", experiment_description=\"Convolutional model\")\n",
    "tracker.start()\n",
    "\n",
    "# Training and evaluation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, criterion, optimizer, epochs=2):\n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Accuracy: {train_acc:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "history = train(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "tracker.stop()\n",
    "\n",
    "# Read emission data\n",
    "df = pd.read_csv('emission.csv', sep=',')\n",
    "print(df)\n",
    "\n",
    "# Using decorators for tracking\n",
    "@track\n",
    "def train_simple_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.BatchNorm2d(1),\n",
    "        nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(16 * 28 * 28, 10)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    history = train(model, train_loader, criterion, optimizer)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "train_simple_model()\n",
    "\n",
    "df = pd.read_csv('emission.csv', sep=',')\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
